{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('./Data/cm1.arff.txt')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['defects'] = df['defects'].apply(lambda x: str(x)[1:]) #removing 'b' from classes\n",
    "numberOfColumns = len(df.columns) #qtd of columns with defects column\n",
    "justClass = df[['defects']].values #only the classes values\n",
    "justData = df.drop(['defects'], axis=1) #removing the classes column for normalization\n",
    "valuesOfColums = justData.columns.values #get attributes names\n",
    "justDataValues = justData.values #get data as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "normalized_data = min_max_scaler.fit_transform(justDataValues)\n",
    "df = pd.DataFrame(normalized_data)\n",
    "df.columns = valuesOfColums\n",
    "df.insert(loc=numberOfColumns-1, column='defects', value=justClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(x, y):\n",
    "    distance = 0\n",
    "    for i in range(len(x)-1):\n",
    "        distance += np.square(x[i] - y[i])\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "def calc_dists(propotypes, testInstance):\n",
    "    d = []\n",
    "    for p in propotypes:\n",
    "        d.append([p, euclidean_distance(testInstance, p)])\n",
    "    distance.sort(key=lambda dist: dist[1])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq(trainSet, prototypes, lrate, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbor = calc_dists(prototypes, example)[0][0]\n",
    "            error = np.subtract(example[:-1], neighbor[:-1])\n",
    "            sum_error += np.sum(np.square(error))\n",
    "            if(example[-1] == neighbor[-1]):\n",
    "                neighbor[:-1] = np.add(neighbor[:-1], np.dot(error, rate))\n",
    "            else:\n",
    "                neighbor[:-1] = np.subtract(neighbor[:-1], np.dot(error, rate))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(neighbor1, neighbor2, instance, w):\n",
    "    di = euclidian_distance(neighbor1, instance)\n",
    "    dj = euclidian_distance(neighbor2, instance)\n",
    "    if di != 0 and dj != 0:\n",
    "        mini = min(di/dj, dj/di)\n",
    "    else:\n",
    "        mini = 0\n",
    "    s = ((1-w)/(1+w))\n",
    "    return (mini > s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq2_1(trainSet, prototypes, lrate, epochs):\n",
    "    prots = lvq(trainSet, lrate, prototypes, epochs)\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbors = calc_dists(prototypes, example)\n",
    "            ei, ej = neighbors[0][0], neighbors[1][0]\n",
    "            if window(ei, ej, example, 0.3):\n",
    "                if(ei[-1] != ej[-1]):\n",
    "                    if(ei[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_i))\n",
    "                        ei[:-1] = np.add(ei[:-1], np.dot(error_i, rate))\n",
    "                        ej[:-1] = np.subtract(ej[:-1], np.dot(error_j, rate))\n",
    "                    elif(ej[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_j))\n",
    "                        ej[:-1] = np.add(ej[:-1], np.dot(error_j, rate))\n",
    "                        ei[:-1] = np.subtract(ei[:-1], np.dot(error_i, rate))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq3(trainSet, prototypes, lrate, epochs):\n",
    "    prots = lvq(trainSet, lrate, prototypes, epochs)\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbors = calc_dists(prototypes, example)\n",
    "            ei, ej = neighbors[0][0], neighbors[1][0]\n",
    "            if window(ei, ej, example, 0.3):\n",
    "                if(ei[-1] != ej[-1]):\n",
    "                    if(ei[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_i))\n",
    "                        ei[:-1] = np.add(ei[:-1], np.dot(error_i, rate))\n",
    "                        ej[:-1] = np.subtract(ej[:-1], np.dot(error_j, rate))\n",
    "                    elif(ej[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_j))\n",
    "                        ej[:-1] = np.add(ej[:-1], np.dot(error_j, rate))\n",
    "                        ei[:-1] = np.subtract(ei[:-1], np.dot(error_i, rate))\n",
    "                elif (ei[-1] == ej[-1]) and (ei[-1] == example[-1]):\n",
    "                    error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                    error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                    sum_error += np.sum(np.square(np.add(error_i, error_j)))\n",
    "                    ei[:-1] = np.add(ei[:-1], np.dot(error_i, (rate * 0.3)))\n",
    "                    ej[:-1] = np.add(ej[:-1], np.dot(error_j, (rate * 0.3)))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
