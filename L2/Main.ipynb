{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('./Data/cm1.arff.txt')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['defects'] = df['defects'].apply(lambda x: str(x)[1:]) #removing 'b' from classes\n",
    "numberOfColumns = len(df.columns) #qtd of columns with defects column\n",
    "justClass = df[['defects']].values #only the classes values\n",
    "justData = df.drop(['defects'], axis=1) #removing the classes column for normalization\n",
    "valuesOfColums = justData.columns.values #get attributes names\n",
    "justDataValues = justData.values #get data as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "normalized_data = min_max_scaler.fit_transform(justDataValues)\n",
    "df = pd.DataFrame(normalized_data)\n",
    "df.columns = valuesOfColums\n",
    "df.insert(loc=numberOfColumns-1, column='defects', value=justClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(x, y):\n",
    "    distance = 0\n",
    "    for i in range(len(x)-1):\n",
    "        distance += np.square(x[i] - y[i])\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "def calc_dists(propotypes, testInstance):\n",
    "    d = []\n",
    "    for p in propotypes:\n",
    "        d.append([p, euclidean_distance(testInstance, p)])\n",
    "    distance.sort(key=lambda dist: dist[1])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq1(trainSet, prototypes, lrate, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbor = calc_dists(prototypes, example)[0][0]\n",
    "            error = np.subtract(example[:-1], neighbor[:-1])\n",
    "            sum_error += np.sum(np.square(error))\n",
    "            if(example[-1] == neighbor[-1]):\n",
    "                neighbor[:-1] = np.add(neighbor[:-1], np.dot(error, rate))\n",
    "            else:\n",
    "                neighbor[:-1] = np.subtract(neighbor[:-1], np.dot(error, rate))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(neighbor1, neighbor2, instance, w):\n",
    "    di = euclidian_distance(neighbor1, instance)\n",
    "    dj = euclidian_distance(neighbor2, instance)\n",
    "    if di != 0 and dj != 0:\n",
    "        mini = min(di/dj, dj/di)\n",
    "    else:\n",
    "        mini = 0\n",
    "    s = ((1-w)/(1+w))\n",
    "    return (mini > s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq2_1(trainSet, prototypes, lrate, epochs):\n",
    "    prots = lvq1(trainSet, lrate, prototypes, epochs)\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbors = calc_dists(prototypes, example)\n",
    "            ei, ej = neighbors[0][0], neighbors[1][0]\n",
    "            if window(ei, ej, example, 0.3):\n",
    "                if(ei[-1] != ej[-1]):\n",
    "                    if(ei[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_i))\n",
    "                        ei[:-1] = np.add(ei[:-1], np.dot(error_i, rate))\n",
    "                        ej[:-1] = np.subtract(ej[:-1], np.dot(error_j, rate))\n",
    "                    elif(ej[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_j))\n",
    "                        ej[:-1] = np.add(ej[:-1], np.dot(error_j, rate))\n",
    "                        ei[:-1] = np.subtract(ei[:-1], np.dot(error_i, rate))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq3(trainSet, prototypes, lrate, epochs):\n",
    "    prots = lvq1(trainSet, lrate, prototypes, epochs)\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbors = calc_dists(prototypes, example)\n",
    "            ei, ej = neighbors[0][0], neighbors[1][0]\n",
    "            if window(ei, ej, example, 0.3):\n",
    "                if(ei[-1] != ej[-1]):\n",
    "                    if(ei[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_i))\n",
    "                        ei[:-1] = np.add(ei[:-1], np.dot(error_i, rate))\n",
    "                        ej[:-1] = np.subtract(ej[:-1], np.dot(error_j, rate))\n",
    "                    elif(ej[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_j))\n",
    "                        ej[:-1] = np.add(ej[:-1], np.dot(error_j, rate))\n",
    "                        ei[:-1] = np.subtract(ei[:-1], np.dot(error_i, rate))\n",
    "                elif (ei[-1] == ej[-1]) and (ei[-1] == example[-1]):\n",
    "                    error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                    error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                    sum_error += np.sum(np.square(np.add(error_i, error_j)))\n",
    "                    ei[:-1] = np.add(ei[:-1], np.dot(error_i, (rate * 0.3)))\n",
    "                    ej[:-1] = np.add(ej[:-1], np.dot(error_j, (rate * 0.3)))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(train, test):\n",
    "    trainSet = []\n",
    "    resultTrainSet = []\n",
    "    testSet = []\n",
    "    resultTestSet = []\n",
    "\n",
    "    for item in train:\n",
    "        trainSet.append(item[:-1])\n",
    "        resultTrainSet.append(item[-1])\n",
    "    for item in test:\n",
    "        testSet.append(item[:-1])\n",
    "        resultTestSet.append(item[-1])\n",
    "    return trainSet,resultTrainSet,testSet,resultTestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "NUMBER_OF_PROTOTYPES = 20 #number of prototypes\n",
    "EPOCHS = 10 #number of epochs training\n",
    "kfoldNumber = 5\n",
    "LVQS = [lvq1, lvq2_1, lvq3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LVQ  1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prototypeSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-900200644c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#prototypeSet = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mLVQ_Prototypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlvq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprototypeSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time = %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prototypeSet' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = np.array(df.values)\n",
    "Y = df.iloc[:, -1]\n",
    "numberOfClasses = len(set(Y))\n",
    "classesValues = list(set(Y))\n",
    "count = 1\n",
    "for lvq in LVQS:\n",
    "    print(\"LVQ \", str(count))\n",
    "    skf = StratifiedKFold(n_splits=kfoldNumber, shuffle=True, random_state=1)\n",
    "    totalAccuracy = []\n",
    "    for train_index, test_index in skf.split(dataset, Y):\n",
    "        X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "        #prototypeSet = []\n",
    "        start = time.time()\n",
    "        LVQ_Prototypes = lvq(X_train, prototypeSet, 0.3, EPOCHS)\n",
    "        final = time.time() - start\n",
    "        print(\"Training time = %.2f\" % (final))\n",
    "        train_data, train_classes, test_data, test_classes = splitData(LVQ_Prototypes, X_test)\n",
    "        for k in [1, 3]:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            knn.fit(train_data, train_classes)\n",
    "            predictions = knn.predict(test_data)\n",
    "            acc = np.sum([1 for i, x in enumerate(predictions) if x == test_classes[i]])\n",
    "            totalAccuracy.append([k, (acc / len(predictions))])\n",
    "    count += 1\n",
    "    print('KNN = 1, Accuracy = %.2f' % (sum([x[1] for x in totalAccuracy if x[0] == 1]) / kfoldNumber))\n",
    "    print('KNN = 3, Accuracy = %.2f' % (sum([x[1] for x in totalAccuracy if x[0] == 3]) / kfoldNumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
