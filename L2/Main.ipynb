{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from random import randint\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('./Data/kc1.arff.txt')\n",
    "df = pd.DataFrame(data[0])\n",
    "df['defects'] = df['defects'].apply(lambda x: str(x)[1:]) #removing 'b' from classes\n",
    "numberOfColumns = len(df.columns) #qtd of columns with defects column\n",
    "justClass = df[['defects']].values #only the classes values\n",
    "justData = df.drop(['defects'], axis=1) #removing the classes column for normalization\n",
    "valuesOfColums = justData.columns.values #get attributes names\n",
    "justDataValues = justData.values #get data as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "normalized_data = min_max_scaler.fit_transform(justDataValues)\n",
    "df = pd.DataFrame(normalized_data)\n",
    "df.columns = valuesOfColums\n",
    "df.insert(loc=numberOfColumns-1, column='defects', value=justClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(x, y):\n",
    "    distance = 0\n",
    "    for i in range(len(x)-1):\n",
    "        distance += np.square(x[i] - y[i])\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "def calc_dists(propotypes, testInstance):\n",
    "    d = []\n",
    "    for p in propotypes:\n",
    "        d.append([p, euclidian_distance(testInstance, p)])\n",
    "    d.sort(key=lambda dist: dist[1])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq1(trainSet, prototypes, lrate, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbor = calc_dists(prototypes, example)[0][0]\n",
    "            error = np.subtract(example[:-1], neighbor[:-1])\n",
    "            sum_error += np.sum(np.square(error))\n",
    "            if(example[-1] == neighbor[-1]):\n",
    "                neighbor[:-1] = np.add(neighbor[:-1], np.dot(error, rate))\n",
    "            else:\n",
    "                neighbor[:-1] = np.subtract(neighbor[:-1], np.dot(error, rate))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(neighbor1, neighbor2, instance, w):\n",
    "    di = euclidian_distance(neighbor1, instance)\n",
    "    dj = euclidian_distance(neighbor2, instance)\n",
    "    if di != 0 and dj != 0:\n",
    "        mini = min(di/dj, dj/di)\n",
    "    else:\n",
    "        mini = 0\n",
    "    s = ((1-w)/(1+w))\n",
    "    return (mini > s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq2_1(trainSet, prototypes, lrate, epochs):\n",
    "    prots = lvq1(trainSet, prototypes, lrate, epochs)\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbors = calc_dists(prototypes, example)\n",
    "            ei, ej = neighbors[0][0], neighbors[1][0]\n",
    "            if window(ei, ej, example, 0.3):\n",
    "                if(ei[-1] != ej[-1]):\n",
    "                    if(ei[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_i))\n",
    "                        ei[:-1] = np.add(ei[:-1], np.dot(error_i, rate))\n",
    "                        ej[:-1] = np.subtract(ej[:-1], np.dot(error_j, rate))\n",
    "                    elif(ej[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_j))\n",
    "                        ej[:-1] = np.add(ej[:-1], np.dot(error_j, rate))\n",
    "                        ei[:-1] = np.subtract(ei[:-1], np.dot(error_i, rate))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvq3(trainSet, prototypes, lrate, epochs):\n",
    "    prots = lvq1(trainSet, prototypes, lrate, epochs)\n",
    "    for epoch in range(epochs):\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        sum_error = 0\n",
    "        for example in trainSet:\n",
    "            neighbors = calc_dists(prototypes, example)\n",
    "            ei, ej = neighbors[0][0], neighbors[1][0]\n",
    "            if window(ei, ej, example, 0.3):\n",
    "                if(ei[-1] != ej[-1]):\n",
    "                    if(ei[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_i))\n",
    "                        ei[:-1] = np.add(ei[:-1], np.dot(error_i, rate))\n",
    "                        ej[:-1] = np.subtract(ej[:-1], np.dot(error_j, rate))\n",
    "                    elif(ej[-1] == example[-1]):\n",
    "                        error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                        error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                        sum_error += np.sum(np.square(error_j))\n",
    "                        ej[:-1] = np.add(ej[:-1], np.dot(error_j, rate))\n",
    "                        ei[:-1] = np.subtract(ei[:-1], np.dot(error_i, rate))\n",
    "                elif (ei[-1] == ej[-1]) and (ei[-1] == example[-1]):\n",
    "                    error_i = np.subtract(example[:-1], ei[:-1])\n",
    "                    error_j = np.subtract(example[:-1], ej[:-1])\n",
    "                    sum_error += np.sum(np.square(np.add(error_i, error_j)))\n",
    "                    ei[:-1] = np.add(ei[:-1], np.dot(error_i, (rate * 0.3)))\n",
    "                    ej[:-1] = np.add(ej[:-1], np.dot(error_j, (rate * 0.3)))\n",
    "    return prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(train, test):\n",
    "    trainSet = []\n",
    "    resultTrainSet = []\n",
    "    testSet = []\n",
    "    resultTestSet = []\n",
    "\n",
    "    for item in train:\n",
    "        trainSet.append(item[:-1])\n",
    "        resultTrainSet.append(item[-1])\n",
    "    for item in test:\n",
    "        testSet.append(item[:-1])\n",
    "        resultTestSet.append(item[-1])\n",
    "    return trainSet, resultTrainSet, testSet, resultTestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "numberOfPrototypes = 60 #number of prototypes\n",
    "epochs = 10 #number of epochs training\n",
    "kfoldNumber = 5\n",
    "lvqs = [lvq1, lvq2_1, lvq3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrototypes(trainSet, numberOfClasses, classesValues):\n",
    "    prototypes = [[] for i in range(numberOfClasses)]\n",
    "    proportions = []\n",
    "    final_prototypes = []\n",
    "    for i,item in enumerate(classesValues):\n",
    "        prototypes[i] = [x for x in trainSet if x[-1] == item]\n",
    "        elements_size = len(prototypes[i])\n",
    "        proportions.append([math.ceil((elements_size / len(trainSet)) * numberOfPrototypes), item])\n",
    "    proportions.sort()\n",
    "    for i,item in enumerate(classesValues):\n",
    "        size = [x[0] for x in proportions if x[1] == item]\n",
    "        for j in range(size[0]):\n",
    "            rand = randint(0, len(prototypes[i])-1)\n",
    "            final_prototypes.append(prototypes[i][rand])\n",
    "    return final_prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LVQ 1\n",
      "Training time = 36.03\n",
      "Training time = 36.25\n",
      "Training time = 36.43\n",
      "Training time = 35.39\n",
      "Training time = 35.61\n",
      "K = 1, Accuracy = 0.85\n",
      "K = 3, Accuracy = 0.85\n",
      "LVQ 2\n",
      "Training time = 71.59\n",
      "Training time = 72.09\n",
      "Training time = 72.35\n",
      "Training time = 71.68\n",
      "Training time = 71.81\n",
      "K = 1, Accuracy = 0.85\n",
      "K = 3, Accuracy = 0.85\n",
      "LVQ 3\n",
      "Training time = 72.39\n",
      "Training time = 72.88\n",
      "Training time = 73.48\n",
      "Training time = 72.71\n",
      "Training time = 72.25\n",
      "K = 1, Accuracy = 0.85\n",
      "K = 3, Accuracy = 0.85\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(df.values)\n",
    "Y = df.iloc[:, -1]\n",
    "numberOfClasses = len(set(Y))\n",
    "classesValues = list(set(Y))\n",
    "count = 1\n",
    "for lvq in lvqs:\n",
    "    print(\"LVQ\", str(count))\n",
    "    skf = StratifiedKFold(n_splits=kfoldNumber, shuffle=True, random_state=1)\n",
    "    totalAccuracy = []\n",
    "    for train_index, test_index in skf.split(dataset, Y):\n",
    "        X_train, X_test = dataset[train_index], dataset[test_index]\n",
    "        prototypeSet = generatePrototypes(X_train, numberOfClasses, classesValues)\n",
    "        start = time.time()\n",
    "        LVQ_Prototypes = lvq(X_train, prototypeSet, 0.3, epochs)\n",
    "        final = time.time() - start\n",
    "        print(\"Training time = %.2f\" % (final))\n",
    "        train_data, train_classes, test_data, test_classes = splitData(LVQ_Prototypes, X_test)\n",
    "        for k in [1, 3]:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            knn.fit(train_data, train_classes)\n",
    "            predictions = knn.predict(test_data)\n",
    "            acc = np.sum([1 for i, x in enumerate(predictions) if x == test_classes[i]])\n",
    "            totalAccuracy.append([k, (acc / len(predictions))])\n",
    "    count += 1\n",
    "    print('K = 1, Accuracy = %.2f' % (sum([x[1] for x in totalAccuracy if x[0] == 1]) / kfoldNumber))\n",
    "    print('K = 3, Accuracy = %.2f' % (sum([x[1] for x in totalAccuracy if x[0] == 3]) / kfoldNumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
